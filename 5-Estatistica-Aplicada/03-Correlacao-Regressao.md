# ğŸ“ˆ CorrelaÃ§Ã£o e RegressÃ£o

## ğŸ¯ Objetivo da LiÃ§Ã£o

Entender relaÃ§Ãµes entre variÃ¡veis e criar modelos simples para previsÃ£o usando **correlaÃ§Ã£o** e **regressÃ£o**.

â€” Quando duas variÃ¡veis variam juntas, hÃ¡ correlaÃ§Ã£o.
â€” RegressÃ£o estima como uma variÃ¡vel explica outra.

---

## ğŸ”— CorrelaÃ§Ã£o (Pearson)

Mede relaÃ§Ã£o linear entre duas variÃ¡veis (âˆ’1 a +1).

```python
import numpy as np
import pandas as pd

# Exemplo: biomassa vs temperatura
biomassa = np.array([245.3, 198.5, 302.1, 275.4, 310.8, 285.2, 320.5, 295.7, 260.8, 280.3])
temperatura = np.array([24.5, 26.1, 22.3, 21.5, 19.8, 18.2, 17.5, 18.0, 19.5, 21.0])

# CorrelaÃ§Ã£o de Pearson
corr = np.corrcoef(biomassa, temperatura)[0, 1]
print(f"CorrelaÃ§Ã£o (Pearson): {corr:.3f}")
```

InterpretaÃ§Ã£o:
- |r| â‰¥ 0.7 â†’ forte
- 0.4â€“0.7 â†’ moderada
- 0.2â€“0.4 â†’ fraca

---

## ğŸ“Š Matriz de CorrelaÃ§Ã£o

```python
# Dataset de exemplo
import seaborn as sns
import matplotlib.pyplot as plt

dados = {
    'biomassa_g': biomassa,
    'temperatura_c': temperatura,
    'salinidade_psu': [35.0, 34.5, 35.2, 35.3, 35.4, 35.5, 35.6, 35.4, 35.2, 35.0],
    'profundidade_m': [3.2, 3.0, 3.5, 3.8, 3.6, 3.4, 3.9, 3.7, 3.5, 3.8]
}

df = pd.DataFrame(dados)

corr_mtx = df.corr(numeric_only=True)
print(corr_mtx.round(3))

plt.figure(figsize=(6, 5))
sns.heatmap(corr_mtx, annot=True, cmap='Blues', vmin=-1, vmax=1)
plt.title('Matriz de CorrelaÃ§Ã£o')
plt.tight_layout()
plt.savefig('matriz_correlacao.png', dpi=300)
plt.show()
```

---

## ğŸ“‰ RegressÃ£o Linear Simples

Modelo: y = a + bÂ·x

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

X = temperatura.reshape(-1, 1)
y = biomassa

modelo = LinearRegression()
modelo.fit(X, y)

# Coeficientes
intercepto = modelo.intercept_
coef = modelo.coef_[0]
print(f"Modelo: biomassa = {intercepto:.2f} + {coef:.2f}Â·temperatura")

# AvaliaÃ§Ã£o
y_pred = modelo.predict(X)
r2 = r2_score(y, y_pred)
rmse = np.sqrt(mean_squared_error(y, y_pred))
print(f"RÂ²: {r2:.3f} | RMSE: {rmse:.2f}g")
```

VisualizaÃ§Ã£o:

```python
plt.figure(figsize=(7,5))
plt.scatter(temperatura, biomassa, s=90, edgecolors='black', alpha=0.7)
plt.plot(temperatura, y_pred, 'r--', linewidth=2)
plt.xlabel('Temperatura (Â°C)')
plt.ylabel('Biomassa (g)')
plt.title('RegressÃ£o Linear: Biomassa vs Temperatura')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('regressao_simples.png', dpi=300)
plt.show()
```

---

## ğŸ“ˆ RegressÃ£o MÃºltipla

VÃ¡rias variÃ¡veis explicam y.

```python
from sklearn.model_selection import train_test_split

X = df[['temperatura_c', 'salinidade_psu', 'profundidade_m']]
y = df['biomassa_g']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

modelo = LinearRegression()
modelo.fit(X_train, y_train)

coeficientes = pd.Series(modelo.coef_, index=X.columns)
print("Coeficientes:")
print(coeficientes.round(3))

# AvaliaÃ§Ã£o
y_pred = modelo.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RÂ² (teste): {r2:.3f} | RMSE: {rmse:.2f}g")
```

---

## âš ï¸ Cuidados Comuns

- CorrelacÌ§aÌƒo â‰  causalidade
- Verificar outliers e nÃ£o-linearidade
- Normalizar variÃ¡veis com escalas muito diferentes
- Usar validaÃ§Ã£o (train/test ou cross-validation)

---

## ğŸ“ Checklist

- [ ] Calculei correlaÃ§Ã£o entre variÃ¡veis
- [ ] Interpretei matriz de correlaÃ§Ã£o
- [ ] Modelei regressÃ£o simples
- [ ] Modelei regressÃ£o mÃºltipla
- [ ] Avaliei RÂ² e RMSE

â€” PrÃ³xima: VisualizaÃ§Ã£o estatÃ­stica com Seaborn e Matplotlib (opcional).
