# ğŸ¤– IntroduÃ§Ã£o ao Machine Learning para Biologia

## ğŸ¯ Objetivo da LiÃ§Ã£o

Aprender os **conceitos fundamentais de Machine Learning** e como aplicÃ¡-los em problemas de biologia e oceanografia.

**O que Ã© Machine Learning?**
- Algoritmos que **aprendem padrÃµes** a partir de dados
- Fazem **previsÃµes** sem programaÃ§Ã£o explÃ­cita
- Melhoram com **mais dados** e experiÃªncia

---

## ğŸ§  Tipos de Machine Learning

### 1. Aprendizado Supervisionado

**DefiniÃ§Ã£o:** Aprende a partir de exemplos rotulados.

```
Entrada (X) â†’ Modelo â†’ SaÃ­da (y)
```

**Exemplos em Biologia:**
- Classificar espÃ©cies a partir de caracterÃ­sticas morfolÃ³gicas
- Prever biomassa com base em temperatura e salinidade
- Identificar imagens de macroalgas

**Tipos:**
- **ClassificaÃ§Ã£o:** SaÃ­da categÃ³rica (espÃ©cie A, B ou C)
- **RegressÃ£o:** SaÃ­da numÃ©rica (biomassa em gramas)

---

### 2. Aprendizado NÃ£o-Supervisionado

**DefiniÃ§Ã£o:** Encontra padrÃµes em dados sem rÃ³tulos.

**Exemplos:**
- Agrupar estaÃ§Ãµes de coleta por similaridade (clustering)
- Reduzir dimensionalidade de dados genÃ´micos (PCA)
- Detectar anomalias em sÃ©ries temporais

---

### 3. Aprendizado por ReforÃ§o

**DefiniÃ§Ã£o:** Aprende por tentativa e erro com recompensas.

**Exemplo:** Otimizar estratÃ©gias de coleta para maximizar biodiversidade.

---

## ğŸ“Š Workflow de Machine Learning

```
1. COLETAR DADOS
   â†“
2. EXPLORAR E LIMPAR
   â†“
3. PREPARAR FEATURES (caracterÃ­sticas)
   â†“
4. DIVIDIR: Treino (80%) | Teste (20%)
   â†“
5. ESCOLHER MODELO
   â†“
6. TREINAR MODELO
   â†“
7. AVALIAR DESEMPENHO
   â†“
8. AJUSTAR E MELHORAR
   â†“
9. USAR EM PRODUÃ‡ÃƒO
```

---

## ğŸ”§ Bibliotecas Python para ML

```python
# Instalar
pip install scikit-learn pandas numpy matplotlib seaborn
```

```python
# Importar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
```

---

## ğŸ¯ Exemplo 1: ClassificaÃ§Ã£o de EspÃ©cies

### Problema

Dado comprimento, largura e espessura de macroalgas, **prever a espÃ©cie**.

### Dataset

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

# Dados sintÃ©ticos de 3 espÃ©cies
dados = {
    'comprimento_cm': [12.5, 15.2, 18.7, 20.3, 25.1,  # Ulva
                       8.3, 9.5, 10.2, 11.8, 12.1,    # Gracilaria
                       30.5, 35.8, 40.2, 38.5, 42.1], # Sargassum
    'largura_cm': [8.2, 9.5, 11.3, 12.8, 15.2,
                   3.5, 4.1, 4.8, 5.2, 5.5,
                   10.5, 12.3, 15.8, 14.2, 16.5],
    'espessura_mm': [0.5, 0.6, 0.7, 0.8, 0.9,
                     1.2, 1.3, 1.5, 1.6, 1.7,
                     2.5, 2.8, 3.2, 3.0, 3.5],
    'especie': ['Ulva']*5 + ['Gracilaria']*5 + ['Sargassum']*5
}

df = pd.DataFrame(dados)

print("="*60)
print("ğŸŒ¿ CLASSIFICAÃ‡ÃƒO DE ESPÃ‰CIES DE MACROALGAS")
print("="*60)
print("\nğŸ“Š Dataset:")
print(df.head(10))

# ====================
# PREPARAR DADOS
# ====================

# Features (X) e Target (y)
X = df[['comprimento_cm', 'largura_cm', 'espessura_mm']]
y = df['especie']

print(f"\nğŸ“ Features (X): {X.shape}")
print(f"ğŸ¯ Target (y): {y.shape}")

# Dividir em treino e teste (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nğŸ“š Dados de treino: {len(X_train)} amostras")
print(f"ğŸ§ª Dados de teste: {len(X_test)} amostras")

# ====================
# TREINAR MODELO
# ====================

print("\n" + "="*60)
print("ğŸ¤– TREINANDO MODELO (DECISION TREE)")
print("="*60)

# Criar e treinar modelo
modelo = DecisionTreeClassifier(max_depth=3, random_state=42)
modelo.fit(X_train, y_train)

print("âœ… Modelo treinado!")

# ====================
# FAZER PREVISÃ•ES
# ====================

print("\n" + "="*60)
print("ğŸ”® FAZENDO PREVISÃ•ES")
print("="*60)

# Prever no conjunto de teste
y_pred = modelo.predict(X_test)

print("\nPrevisÃµes vs Real:")
print("-"*60)
for i, (real, pred) in enumerate(zip(y_test, y_pred)):
    correto = "âœ…" if real == pred else "âŒ"
    print(f"Amostra {i+1}: Real={real:12s} | Previsto={pred:12s} {correto}")

# ====================
# AVALIAR DESEMPENHO
# ====================

print("\n" + "="*60)
print("ğŸ“Š AVALIAÃ‡ÃƒO DO MODELO")
print("="*60)

# AcurÃ¡cia
acuracia = accuracy_score(y_test, y_pred)
print(f"\nğŸ¯ AcurÃ¡cia: {acuracia*100:.1f}%")

# RelatÃ³rio detalhado
print("\nğŸ“‹ RelatÃ³rio de ClassificaÃ§Ã£o:")
print("-"*60)
print(classification_report(y_test, y_pred))

# ====================
# TESTAR COM NOVA AMOSTRA
# ====================

print("\n" + "="*60)
print("ğŸ†• PREVER ESPÃ‰CIE DE NOVA AMOSTRA")
print("="*60)

# Nova amostra desconhecida
nova_amostra = pd.DataFrame({
    'comprimento_cm': [22.5],
    'largura_cm': [13.8],
    'espessura_mm': [0.75]
})

predicao = modelo.predict(nova_amostra)
probabilidades = modelo.predict_proba(nova_amostra)

print(f"\nğŸ“ CaracterÃ­sticas:")
print(f"   Comprimento: {nova_amostra['comprimento_cm'].values[0]} cm")
print(f"   Largura: {nova_amostra['largura_cm'].values[0]} cm")
print(f"   Espessura: {nova_amostra['espessura_mm'].values[0]} mm")

print(f"\nğŸ”® PrevisÃ£o: {predicao[0]}")
print(f"\nğŸ“Š Probabilidades:")
for especie, prob in zip(modelo.classes_, probabilidades[0]):
    print(f"   {especie}: {prob*100:.1f}%")

print("\n" + "="*60)
print("âœ… CLASSIFICAÃ‡ÃƒO CONCLUÃDA!")
print("="*60)
```

---

## ğŸ“ˆ Exemplo 2: RegressÃ£o - Prever Biomassa

### Problema

Prever **biomassa** com base em temperatura, salinidade e profundidade.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Dataset
dados = {
    'temperatura_c': [24.5, 26.1, 22.3, 21.5, 19.8, 18.2, 17.5, 18.0, 19.5, 21.0],
    'salinidade_psu': [35.0, 34.5, 35.2, 35.3, 35.4, 35.5, 35.6, 35.4, 35.2, 35.0],
    'profundidade_m': [3.2, 3.0, 3.5, 3.8, 3.6, 3.4, 3.9, 3.7, 3.5, 3.8],
    'biomassa_g': [245.3, 198.5, 302.1, 275.4, 310.8, 285.2, 320.5, 295.7, 260.8, 280.3]
}

df = pd.DataFrame(dados)

print("="*60)
print("ğŸ“Š REGRESSÃƒO: PREVER BIOMASSA")
print("="*60)

# Preparar dados
X = df[['temperatura_c', 'salinidade_psu', 'profundidade_m']]
y = df['biomassa_g']

# Normalizar features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Treinar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# Prever
y_pred = modelo.predict(X_test)

# Avaliar
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"\nğŸ“Š Desempenho do Modelo:")
print(f"   RÂ² Score: {r2:.4f}")
print(f"   RMSE: {rmse:.2f}g")

print(f"\nğŸ¯ Coeficientes:")
features = ['temperatura_c', 'salinidade_psu', 'profundidade_m']
for feature, coef in zip(features, modelo.coef_):
    print(f"   {feature}: {coef:.4f}")

# Prever nova amostra
nova_amostra = scaler.transform([[20.5, 35.1, 3.5]])
predicao = modelo.predict(nova_amostra)
print(f"\nğŸ”® PrevisÃ£o para nova amostra: {predicao[0]:.2f}g")

print("\n" + "="*60)
print("âœ… REGRESSÃƒO CONCLUÃDA!")
print("="*60)
```

---

## ğŸ¨ VisualizaÃ§Ã£o de Modelos

### Ãrvore de DecisÃ£o

```python
from sklearn import tree
import matplotlib.pyplot as plt

# Visualizar Ã¡rvore
plt.figure(figsize=(15, 10))
tree.plot_tree(modelo, 
               feature_names=['comprimento', 'largura', 'espessura'],
               class_names=modelo.classes_,
               filled=True, 
               rounded=True, 
               fontsize=10)
plt.title('Ãrvore de DecisÃ£o - ClassificaÃ§Ã£o de EspÃ©cies', fontsize=16)
plt.savefig('arvore_decisao.png', dpi=300, bbox_inches='tight')
plt.show()
```

### Matriz de ConfusÃ£o

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calcular matriz de confusÃ£o
cm = confusion_matrix(y_test, y_pred)

# Plotar
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=modelo.classes_,
            yticklabels=modelo.classes_)
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title('Matriz de ConfusÃ£o')
plt.savefig('matriz_confusao.png', dpi=300)
plt.show()
```

---

## ğŸ“ Conceitos-Chave

### Overfitting vs Underfitting

```
UNDERFITTING (modelo simples demais)
   Treino: 60% | Teste: 62%
   â†’ Adicionar complexidade

BONS RESULTADOS
   Treino: 95% | Teste: 92%
   â†’ Modelo equilibrado âœ…

OVERFITTING (modelo complexo demais)
   Treino: 99% | Teste: 75%
   â†’ Simplificar modelo ou mais dados
```

### Cross-Validation

```python
from sklearn.model_selection import cross_val_score

# ValidaÃ§Ã£o cruzada (k-fold)
scores = cross_val_score(modelo, X, y, cv=5)

print(f"AcurÃ¡cia mÃ©dia: {scores.mean():.4f} Â± {scores.std():.4f}")
```

---

## ğŸ“ Checklist desta LiÃ§Ã£o

- [ ] Entendi os tipos de ML (supervisionado/nÃ£o-supervisionado)
- [ ] Criei modelo de classificaÃ§Ã£o
- [ ] Treinei modelo de regressÃ£o
- [ ] Avaliei desempenho com mÃ©tricas
- [ ] Fiz previsÃµes em novos dados

---

## â¡ï¸ PrÃ³xima LiÃ§Ã£o

- **02-Classificacao-Avancada.md** (Random Forest, SVM, Neural Networks)

---

**VocÃª entrou no mundo do Machine Learning!** ğŸ¤–âœ¨
