# üìñ Gloss√°rio - Machine Learning

## A

**Acur√°cia (Accuracy)**: Propor√ß√£o de predi√ß√µes corretas (TP+TN / Total).

**Ajuste (Fitting)**: Processo de treinar modelo aos dados.

**Algoritmo**: Sequ√™ncia de passos para resolver problema.

**Aprendizado N√£o-Supervisionado**: ML sem r√≥tulos (clustering, PCA).

**Aprendizado Supervisionado**: ML com dados rotulados (classifica√ß√£o, regress√£o).

**√Årvore de Decis√£o**: Modelo que toma decis√µes seguindo estrutura de √°rvore.

## B

**Bagging**: T√©cnica de ensemble que treina m√∫ltiplos modelos em subamostras.

**Baseline**: Modelo simples de refer√™ncia para compara√ß√£o.

**Batch**: Subconjunto de dados usado em uma itera√ß√£o de treinamento.

**Bias (Vi√©s)**: Tend√™ncia do modelo a sistematicamente errar em uma dire√ß√£o.

## C

**Centroide**: Centro de cluster em algoritmos de agrupamento.

**Classifica√ß√£o**: Tarefa de prever categoria/classe.

**Cluster**: Grupo de dados similares identificado por algoritmo.

**Clusteriza√ß√£o**: Agrupamento de dados por similaridade.

**Coeficiente de Silhueta**: M√©trica de qualidade de clustering (-1 a +1).

**Componente Principal**: Dire√ß√£o de m√°xima vari√¢ncia em PCA.

**Confusion Matrix (Matriz de Confus√£o)**: Tabela mostrando VP, VN, FP, FN.

**Cross-Validation (Valida√ß√£o Cruzada)**: T√©cnica para avaliar modelo dividindo dados em k-folds.

## D

**Dataset**: Conjunto de dados para treinar/testar modelo.

**Decision Boundary (Fronteira de Decis√£o)**: Limite que separa classes.

**Dendrograma**: Diagrama de √°rvore mostrando agrupamento hier√°rquico.

**Dimensionalidade**: N√∫mero de features em dataset.

## E

**Elbow Method (M√©todo do Cotovelo)**: T√©cnica para escolher n√∫mero de clusters.

**Ensemble**: Combina√ß√£o de m√∫ltiplos modelos para melhorar predi√ß√µes.

**Epoch**: Uma passagem completa por todos dados de treino.

**Erro**: Diferen√ßa entre predi√ß√£o e valor real.

**Escala**: Intervalo de valores de vari√°vel.

**Especificidade**: Propor√ß√£o de negativos corretamente identificados (VN / VN+FP).

**Estimador**: Algoritmo que aprende de dados (ex: RandomForest, KMeans).

## F

**F1-Score**: M√©dia harm√¥nica de precis√£o e recall (2√óP√óR / P+R).

**Falso Negativo (FN)**: Predizer negativo quando √© positivo.

**Falso Positivo (FP)**: Predizer positivo quando √© negativo.

**Feature (Caracter√≠stica)**: Atributo/vari√°vel de entrada no modelo.

**Feature Engineering**: Cria√ß√£o de novas features a partir das existentes.

**Feature Selection**: Escolha das features mais relevantes.

**Fit**: Treinar modelo com dados.

## G

**Generaliza√ß√£o**: Capacidade de modelo performar bem em dados novos.

**Grid Search**: Busca exaustiva por melhores hiperpar√¢metros.

## H

**Hiperpar√¢metro**: Configura√ß√£o externa ao modelo (ex: n_clusters, max_depth).

**Holdout**: Divis√£o simples de dados em treino e teste.

## I

**In√©rcia**: Soma das dist√¢ncias quadr√°ticas de pontos aos centroides (KMeans).

**Itera√ß√£o**: Repeti√ß√£o de processo de otimiza√ß√£o.

## K

**K-Fold**: T√©cnica de cross-validation com k divis√µes.

**K-Means**: Algoritmo de clustering que agrupa em k grupos.

**KNN (K-Nearest Neighbors)**: Algoritmo que classifica baseado em k vizinhos mais pr√≥ximos.

## L

**Label (R√≥tulo)**: Categoria/valor alvo que queremos prever.

**Learning Rate**: Taxa de atualiza√ß√£o de par√¢metros em otimiza√ß√£o.

**Logistic Regression**: Modelo para classifica√ß√£o bin√°ria.

## M

**MAE (Mean Absolute Error)**: M√©dia dos erros absolutos.

**Matriz de Confus√£o**: Ver Confusion Matrix.

**M√©trica**: Medida de performance do modelo.

**Modelo**: Representa√ß√£o matem√°tica aprendida dos dados.

**MSE (Mean Squared Error)**: M√©dia dos erros quadr√°ticos.

## N

**Normaliza√ß√£o**: Ajuste de features para mesma escala (0 a 1).

**n_clusters**: N√∫mero de clusters desejado.

**n_components**: N√∫mero de componentes principais em PCA.

## O

**Outlier**: Ponto muito distante do padr√£o geral.

**Overfitting (Sobreajuste)**: Modelo muito ajustado aos dados de treino, ruim em generalizar.

## P

**Par√¢metro**: Valor interno aprendido pelo modelo (pesos, coeficientes).

**PCA (Principal Component Analysis)**: T√©cnica de redu√ß√£o de dimensionalidade.

**Pipeline**: Sequ√™ncia automatizada de transforma√ß√µes e modelo.

**Precis√£o (Precision)**: Propor√ß√£o de positivos preditos que s√£o realmente positivos (VP / VP+FP).

**Predi√ß√£o**: Sa√≠da do modelo para nova entrada.

**Predict**: Usar modelo treinado para fazer predi√ß√µes.

**Pre-processamento**: Prepara√ß√£o de dados antes do treino.

## R

**Random Forest**: Ensemble de √°rvores de decis√£o.

**Random State**: Semente para reprodutibilidade.

**Recall (Sensibilidade)**: Propor√ß√£o de positivos corretamente identificados (VP / VP+FN).

**Redu√ß√£o de Dimensionalidade**: Diminuir n√∫mero de features mantendo informa√ß√£o.

**Regress√£o**: Tarefa de prever valor num√©rico cont√≠nuo.

**RMSE (Root Mean Squared Error)**: Raiz quadrada de MSE.

**ROC Curve**: Gr√°fico de taxa VP vs FP para diferentes thresholds.

**R¬≤ (R-Squared)**: Coeficiente de determina√ß√£o (0 a 1).

## S

**Scaler**: Transformador que ajusta escala de features.

**Score**: M√©trica de avalia√ß√£o do modelo.

**Sensibilidade**: Ver Recall.

**Silhouette Score**: Ver Coeficiente de Silhueta.

**StandardScaler**: Normaliza√ß√£o usando m√©dia e desvio padr√£o (z-score).

**Supervisionado**: Aprendizado com dados rotulados.

## T

**Target**: Vari√°vel que queremos prever.

**Test Set (Conjunto de Teste)**: Dados n√£o usados no treino para avaliar modelo.

**Threshold (Limiar)**: Valor de corte para decis√£o de classifica√ß√£o.

**Train Set (Conjunto de Treino)**: Dados usados para treinar modelo.

**Transforma√ß√£o**: Opera√ß√£o aplicada aos dados (normaliza√ß√£o, PCA, etc).

**True Negative (TN - Verdadeiro Negativo)**: Predi√ß√£o negativa correta.

**True Positive (TP - Verdadeiro Positivo)**: Predi√ß√£o positiva correta.

## U

**Underfitting (Subajuste)**: Modelo muito simples que n√£o captura padr√µes.

## V

**Valida√ß√£o**: Avalia√ß√£o de performance do modelo.

**Vari√¢ncia Explicada**: Propor√ß√£o de vari√¢ncia capturada por componentes principais.

**Vi√©s-Vari√¢ncia**: Trade-off entre simplicidade e flexibilidade do modelo.

## F√≥rmulas Essenciais

### M√©tricas de Classifica√ß√£o
```
Acur√°cia = (VP + VN) / Total

Precis√£o = VP / (VP + FP)

Recall = VP / (VP + FN)

F1-Score = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)

Especificidade = VN / (VN + FP)
```

### M√©tricas de Regress√£o
```
MAE = Œ£|y_real - y_pred| / n

MSE = Œ£(y_real - y_pred)¬≤ / n

RMSE = ‚àöMSE

R¬≤ = 1 - (SS_res / SS_tot)
```

### KMeans
```
In√©rcia = Œ£ min(||x - Œº‚±º||¬≤)
onde Œº‚±º s√£o os centroides

Silhueta = (b - a) / max(a, b)
a = dist√¢ncia m√©dia intra-cluster
b = dist√¢ncia m√©dia ao cluster mais pr√≥ximo
```

## Exemplos Pr√°ticos

### Classifica√ß√£o Completa
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Carregar dados
df = pd.read_csv('especies.csv')
X = df[['temperatura', 'salinidade', 'profundidade', 'ph']]
y = df['especie']

# Dividir treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Normalizar
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Treinar modelo
modelo = RandomForestClassifier(n_estimators=100, random_state=42)
modelo.fit(X_train_scaled, y_train)

# Predizer
y_pred = modelo.predict(X_test_scaled)

# Avaliar
print("Acur√°cia:", modelo.score(X_test_scaled, y_test))
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred))

# Matriz de confus√£o
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confus√£o')
plt.ylabel('Real')
plt.xlabel('Predito')
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')

# Import√¢ncia de features
importancias = pd.DataFrame({
    'feature': X.columns,
    'importancia': modelo.feature_importances_
}).sort_values('importancia', ascending=False)

print("\nImport√¢ncia de Features:")
print(importancias)
```

### Clusteriza√ß√£o com K-Means
```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Dados
df = pd.read_csv('locais_coleta.csv')
X = df[['latitude', 'longitude', 'temperatura', 'salinidade']]

# Normalizar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# M√©todo do cotovelo para escolher k
inercias = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inercias.append(kmeans.inertia_)

# Plotar cotovelo
plt.figure(figsize=(10, 6))
plt.plot(K_range, inercias, 'bo-')
plt.xlabel('N√∫mero de Clusters (k)')
plt.ylabel('In√©rcia')
plt.title('M√©todo do Cotovelo')
plt.grid(True)
plt.savefig('elbow.png', dpi=300, bbox_inches='tight')

# Aplicar K-Means com k escolhido
k_ideal = 4
kmeans = KMeans(n_clusters=k_ideal, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Adicionar clusters ao DataFrame
df['cluster'] = clusters

# Avaliar silhueta
from sklearn.metrics import silhouette_score
silhueta = silhouette_score(X_scaled, clusters)
print(f"Coeficiente de Silhueta: {silhueta:.3f}")

# Plotar clusters
plt.figure(figsize=(12, 8))
scatter = plt.scatter(df['longitude'], df['latitude'], 
                     c=clusters, cmap='viridis', s=100, alpha=0.6)
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title(f'Clusters Identificados (k={k_ideal})')
plt.colorbar(scatter, label='Cluster')
plt.savefig('clusters.png', dpi=300, bbox_inches='tight')
```

### PCA (Redu√ß√£o de Dimensionalidade)
```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Dados com muitas features
df = pd.read_csv('medicoes_complexas.csv')
X = df.drop('especie', axis=1)
y = df['especie']

# Normalizar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Aplicar PCA
pca = PCA()
X_pca = pca.fit_transform(X_scaled)

# Vari√¢ncia explicada
var_explicada = pca.explained_variance_ratio_
var_acumulada = var_explicada.cumsum()

# Plotar vari√¢ncia
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

ax1.bar(range(1, len(var_explicada)+1), var_explicada)
ax1.set_xlabel('Componente Principal')
ax1.set_ylabel('Vari√¢ncia Explicada')
ax1.set_title('Vari√¢ncia por Componente')

ax2.plot(range(1, len(var_acumulada)+1), var_acumulada, 'bo-')
ax2.axhline(y=0.95, color='r', linestyle='--', label='95%')
ax2.set_xlabel('N√∫mero de Componentes')
ax2.set_ylabel('Vari√¢ncia Acumulada')
ax2.set_title('Vari√¢ncia Acumulada')
ax2.legend()
ax2.grid(True)

plt.savefig('pca_variance.png', dpi=300, bbox_inches='tight')

# Reduzir para 2 componentes
pca_2d = PCA(n_components=2)
X_2d = pca_2d.fit_transform(X_scaled)

print(f"Vari√¢ncia explicada com 2 componentes: {pca_2d.explained_variance_ratio_.sum():.2%}")

# Plotar
plt.figure(figsize=(10, 8))
scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y.astype('category').cat.codes, 
                     cmap='viridis', s=100, alpha=0.6)
plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.1%})')
plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.1%})')
plt.title('Dados Projetados em 2 Componentes Principais')
plt.colorbar(scatter, label='Esp√©cie')
plt.savefig('pca_2d.png', dpi=300, bbox_inches='tight')
```

### Pipeline Completo
```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Criar pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA()),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Definir grid de hiperpar√¢metros
param_grid = {
    'pca__n_components': [2, 3, 4, 5],
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [None, 10, 20]
}

# Grid search com valida√ß√£o cruzada
grid_search = GridSearchCV(pipeline, param_grid, cv=5, 
                           scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Melhores par√¢metros
print("Melhores par√¢metros:", grid_search.best_params_)
print("Melhor acur√°cia:", grid_search.best_score_)

# Avaliar no teste
y_pred = grid_search.predict(X_test)
print("\nAcur√°cia no teste:", accuracy_score(y_test, y_pred))
```

## Guia de Escolha de Algoritmo

| Tarefa | Algoritmo Recomendado |
|--------|----------------------|
| Classifica√ß√£o simples | Logistic Regression, KNN |
| Classifica√ß√£o complexa | Random Forest, XGBoost |
| Regress√£o simples | Linear Regression |
| Regress√£o complexa | Random Forest Regressor |
| Clustering | K-Means, DBSCAN |
| Redu√ß√£o de dimensionalidade | PCA, t-SNE |
| Dados desbalanceados | SMOTE + Classificador |

---

üí° **Dica**: Sempre normalize seus dados antes de aplicar KMeans ou PCA!
